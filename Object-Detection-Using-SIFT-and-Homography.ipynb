{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANNOT find the target object.\n",
      "Matched Coordinates: [(83.3129653930664, 132.7753143310547)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_object(template_path, search_path, min_matching_points=5):\n",
    "    # Read the images\n",
    "    template_img = cv2.imread(template_path)\n",
    "    search_img = cv2.imread(search_path)\n",
    "\n",
    "    # Check if the images are loaded successfully\n",
    "    if template_img is None or search_img is None:\n",
    "        print(f\"Error: Unable to read images at {template_path} and {search_path}\")\n",
    "        return None\n",
    "\n",
    "    # Convert images to grayscale\n",
    "    template_gray = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\n",
    "    search_gray = cv2.cvtColor(search_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints_template, descriptors_template = sift.detectAndCompute(template_gray, None)\n",
    "    keypoints_search, descriptors_search = sift.detectAndCompute(search_gray, None)\n",
    "\n",
    "    # Initialize a Brute Force Matcher\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = bf.knnMatch(descriptors_template, descriptors_search, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good_matches = [m1 for m1, m2 in matches if m1.distance < 0.75 * m2.distance]\n",
    "    matched_points = [keypoints_template[m.queryIdx].pt for m in good_matches]\n",
    "\n",
    "    # Draw bounding box around the found object in the search image\n",
    "    if len(good_matches) > 4:\n",
    "        src_pts = np.float32([keypoints_template[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints_search[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        h, w = template_gray.shape\n",
    "\n",
    "        # Decrease bounding box height from the top\n",
    "        corners = np.float32([[0, h * 0.06], [0, h - 1], [w - 1, h - 1], [w - 1, h * 0.06]]).reshape(-1, 1, 2)\n",
    "        transformed_corners = cv2.perspectiveTransform(corners, M)\n",
    "\n",
    "        # Draw bounding box with decreased height from the top\n",
    "        search_img = cv2.polylines(search_img, [np.int32(transformed_corners)], True, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Check if the number of matching points is enough\n",
    "    if len(good_matches) >= min_matching_points:\n",
    "        identification_message = \"The object can be identified in this image.\"\n",
    "\n",
    "        # Display the matches, bounding box, and identification message\n",
    "        draw_params = dict(matchColor=(0, 255, 0), singlePointColor=None, matchesMask=None, flags=2)\n",
    "        img_result = cv2.drawMatches(template_img, keypoints_template, search_img, keypoints_search, good_matches, None, **draw_params)\n",
    "        text_position = (img_result.shape[1] // 2 - 100, img_result.shape[0] - 10)  # Bottom middle\n",
    "        cv2.putText(img_result, identification_message, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (112, 112, 112), 2)\n",
    "        cv2.imshow(\"Matches and Bounding Box\", img_result)\n",
    "\n",
    "    else:\n",
    "        print(\"CANNOT find the target object.\")\n",
    "        identification_message = \"CANNOT find the target object.\"\n",
    "        text_position = (10, 30)  # Top left\n",
    "        cv2.putText(search_img, identification_message, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Search Image\", search_img)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return matched_points\n",
    "\n",
    "# Example usage with different image paths\n",
    "template_path = r'target.png'\n",
    "search_path = r'test2.jpg'\n",
    "matched_coordinates = find_object(template_path, search_path)\n",
    "\n",
    "# Print the coordinates of matched points\n",
    "if matched_coordinates is not None:\n",
    "    print(\"Matched Coordinates:\", matched_coordinates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
